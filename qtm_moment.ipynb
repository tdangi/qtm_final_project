{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QTM 151 Final Project\n",
    "## Project Members: Tammy Dang, Bao Truong, Jocelyn Nguyen, Chau Anh Nguyen\n",
    "\n",
    "### Data Description\n",
    "\n",
    "The question we are examining with our dataset is:\n",
    "\n",
    "\n",
    "*   **How does the frequency of pit stops correlate with the success rate of driver victories in Formula 1 racing?**\n",
    "\n",
    "In order to examine this, we will be parsing and analyzing these datasets:\n",
    "\n",
    "1.   pit_stops.csv\n",
    "2.   driver_standings.csv\n",
    "\n",
    "Each row represents a driver within an F1 race. This will be distinct based on raceID and driverId.\n",
    "\n",
    "# Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'pandas' has no attribute '_pandas_datetime_CAPI' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# \"pandas\" processes datasets\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# \"maplotlib.pyplot\" generates graphs\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# datetime packages for time series manipulation\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdates\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmdates\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatetime\u001b[39;00m \u001b[39mimport\u001b[39;00m date, time, datetime\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/__init__.py:46\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39m# let init-time option registration happen\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig_init\u001b[39;00m  \u001b[39m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     47\u001b[0m     \u001b[39m# dtype\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     ArrowDtype,\n\u001b[1;32m     49\u001b[0m     Int8Dtype,\n\u001b[1;32m     50\u001b[0m     Int16Dtype,\n\u001b[1;32m     51\u001b[0m     Int32Dtype,\n\u001b[1;32m     52\u001b[0m     Int64Dtype,\n\u001b[1;32m     53\u001b[0m     UInt8Dtype,\n\u001b[1;32m     54\u001b[0m     UInt16Dtype,\n\u001b[1;32m     55\u001b[0m     UInt32Dtype,\n\u001b[1;32m     56\u001b[0m     UInt64Dtype,\n\u001b[1;32m     57\u001b[0m     Float32Dtype,\n\u001b[1;32m     58\u001b[0m     Float64Dtype,\n\u001b[1;32m     59\u001b[0m     CategoricalDtype,\n\u001b[1;32m     60\u001b[0m     PeriodDtype,\n\u001b[1;32m     61\u001b[0m     IntervalDtype,\n\u001b[1;32m     62\u001b[0m     DatetimeTZDtype,\n\u001b[1;32m     63\u001b[0m     StringDtype,\n\u001b[1;32m     64\u001b[0m     BooleanDtype,\n\u001b[1;32m     65\u001b[0m     \u001b[39m# missing\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     NA,\n\u001b[1;32m     67\u001b[0m     isna,\n\u001b[1;32m     68\u001b[0m     isnull,\n\u001b[1;32m     69\u001b[0m     notna,\n\u001b[1;32m     70\u001b[0m     notnull,\n\u001b[1;32m     71\u001b[0m     \u001b[39m# indexes\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     Index,\n\u001b[1;32m     73\u001b[0m     CategoricalIndex,\n\u001b[1;32m     74\u001b[0m     RangeIndex,\n\u001b[1;32m     75\u001b[0m     MultiIndex,\n\u001b[1;32m     76\u001b[0m     IntervalIndex,\n\u001b[1;32m     77\u001b[0m     TimedeltaIndex,\n\u001b[1;32m     78\u001b[0m     DatetimeIndex,\n\u001b[1;32m     79\u001b[0m     PeriodIndex,\n\u001b[1;32m     80\u001b[0m     IndexSlice,\n\u001b[1;32m     81\u001b[0m     \u001b[39m# tseries\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     NaT,\n\u001b[1;32m     83\u001b[0m     Period,\n\u001b[1;32m     84\u001b[0m     period_range,\n\u001b[1;32m     85\u001b[0m     Timedelta,\n\u001b[1;32m     86\u001b[0m     timedelta_range,\n\u001b[1;32m     87\u001b[0m     Timestamp,\n\u001b[1;32m     88\u001b[0m     date_range,\n\u001b[1;32m     89\u001b[0m     bdate_range,\n\u001b[1;32m     90\u001b[0m     Interval,\n\u001b[1;32m     91\u001b[0m     interval_range,\n\u001b[1;32m     92\u001b[0m     DateOffset,\n\u001b[1;32m     93\u001b[0m     \u001b[39m# conversion\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     to_numeric,\n\u001b[1;32m     95\u001b[0m     to_datetime,\n\u001b[1;32m     96\u001b[0m     to_timedelta,\n\u001b[1;32m     97\u001b[0m     \u001b[39m# misc\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     Flags,\n\u001b[1;32m     99\u001b[0m     Grouper,\n\u001b[1;32m    100\u001b[0m     factorize,\n\u001b[1;32m    101\u001b[0m     unique,\n\u001b[1;32m    102\u001b[0m     value_counts,\n\u001b[1;32m    103\u001b[0m     NamedAgg,\n\u001b[1;32m    104\u001b[0m     array,\n\u001b[1;32m    105\u001b[0m     Categorical,\n\u001b[1;32m    106\u001b[0m     set_eng_float_format,\n\u001b[1;32m    107\u001b[0m     Series,\n\u001b[1;32m    108\u001b[0m     DataFrame,\n\u001b[1;32m    109\u001b[0m )\n\u001b[1;32m    111\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdtypes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdtypes\u001b[39;00m \u001b[39mimport\u001b[39;00m SparseDtype\n\u001b[1;32m    113\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtseries\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m infer_freq\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/api.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_libs\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     NaT,\n\u001b[1;32m      3\u001b[0m     Period,\n\u001b[1;32m      4\u001b[0m     Timedelta,\n\u001b[1;32m      5\u001b[0m     Timestamp,\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_libs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmissing\u001b[39;00m \u001b[39mimport\u001b[39;00m NA\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdtypes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdtypes\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     10\u001b[0m     ArrowDtype,\n\u001b[1;32m     11\u001b[0m     CategoricalDtype,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     PeriodDtype,\n\u001b[1;32m     15\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/__init__.py:18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_libs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpandas_parser\u001b[39;00m  \u001b[39m# noqa: E501 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_libs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpandas_datetime\u001b[39;00m  \u001b[39m# noqa: F401,E501 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_libs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minterval\u001b[39;00m \u001b[39mimport\u001b[39;00m Interval\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_libs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtslibs\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     20\u001b[0m     NaT,\n\u001b[1;32m     21\u001b[0m     NaTType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     iNaT,\n\u001b[1;32m     27\u001b[0m )\n",
      "File \u001b[0;32minterval.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.interval\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mhashtable.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.hashtable\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mmissing.pyx:42\u001b[0m, in \u001b[0;36minit pandas._libs.missing\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'pandas' has no attribute '_pandas_datetime_CAPI' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "# \"pandas\" processes datasets\n",
    "# \"maplotlib.pyplot\" generates graphs\n",
    "# datetime packages for time series manipulation\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import date, time, datetime\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset\n",
    "For our analysis we will be utilizing three datasets for F1 racing:\n",
    "\n",
    "\n",
    "1.   pit_stops.csv\n",
    "2.   driver_standings.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file\n",
    "driver_standings = pd.read_csv(\"data_raw/driver_standings.csv\")\n",
    "pit_stops = pd.read_csv(\"data_raw/pit_stops.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to see the data\n",
    "display(driver_standings)\n",
    "display(pit_stops)\n",
    "\n",
    "# note: We will group them by raceId and driverId when merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MERGE\n",
    "The following will be the merging process between driver_standings and pit_stops. They will be merged by grouping by raceId and driverId and inner joining the dataset. We will then use this to clean and create data descriptions to find out the dataset we can use for graphing, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge driver_standings and pit_stops by raceId and driverId. Store this in data frame, merged_f1\n",
    "merged_f1 = pd.merge(driver_standings, pit_stops, on =['raceId', 'driverId'], how ='inner')\n",
    "display(merged_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Description Diagnostic Commands\n",
    "The following is code to understand the data we have better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many observations do we have in the dataset?\n",
    "n_total = len(merged_f1)\n",
    "\n",
    "#count non-missing observations\n",
    "n_nonmiss_wins = merged_f1[\"wins\"].count()  # there are no NAs.\n",
    "n_nonmiss_stop = merged_f1[\"stop\"].count()  # there are no NAs.\n",
    "n_nonmiss_points = merged_f1[\"points\"].count() # there are no NAs.\n",
    "\n",
    "# get unique values of race and driverId\n",
    "list_ids_race = pd.unique(merged_f1[\"raceId\"])\n",
    "list_ids_driver = pd.unique(merged_f1[\"driverId\"])\n",
    "\n",
    "# NOTE: please group by race and driverId. As there are different races within this dataset with a participation of d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use regular expression to clean \"duration\"\n",
    "time_format = re.compile(r'^([0-5]?\\d):([0-5]?\\d)\\.(\\d{1,3})$') # regex of values like \"16:44.718\"\n",
    "dropping_list = [] # create array of rows with the said regex\n",
    "\n",
    "for index, row in merged_f1.iterrows(): #create for loop to iterate through merged_f1's rows\n",
    "    if time_format.match(row['duration']):\n",
    "        dropping_list.append(index)\n",
    "\n",
    "merged_f1.drop(dropping_list, inplace=True)\n",
    "\n",
    "# I realized that I don't actually need to do this because miliseconds is the cleaned version of duration\n",
    "# But i'll keep it here so let me have my glory T.T. This took me 2 hours to figure out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate by raceId and driverId, looking at total stops, pit time, and wins of each driverId\n",
    "agg_table = merged_f1.groupby([\"raceId\", \"driverId\"]).agg(total_stops = (\"stop\", \"sum\"),\n",
    "                                               total_pit_time = (\"milliseconds\", \"sum\"),\n",
    "                                               total_wins = (\"wins\", \"sum\"),\n",
    "                                               total_points = (\"points\", \"sum\"),\n",
    "                                               total_lap = (\"lap\", \"sum\")).reset_index()\n",
    "agg_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots to assess the relationship between, Total Pit Time, Total Stops, Total Wins\n",
    "fig, list_subfig = plt.subplots(1, 3, figsize = (11,3))\n",
    "\n",
    "list_subfig[0].scatter(agg_table[\"total_pit_time\"], agg_table[\"total_stops\"])\n",
    "list_subfig[0].set_title(\"Total Pit Time vs. total_stops\")\n",
    "list_subfig[0].set_xlabel(\"Total Pit Time\")\n",
    "list_subfig[0].set_ylabel(\"Total Stops\")\n",
    "\n",
    "list_subfig[1].scatter(agg_table[\"total_pit_time\"], agg_table[\"total_wins\"])\n",
    "list_subfig[1].set_title(\"Total Pit Time vs. Total Wins\")\n",
    "list_subfig[1].set_xlabel(\"Total Pit Time\")\n",
    "list_subfig[1].set_ylabel(\"Total Wins\")\n",
    "\n",
    "list_subfig[2].scatter(agg_table[\"total_stops\"], agg_table[\"total_wins\"])\n",
    "list_subfig[2].set_title(\"Total Stops vs. Total Wins\")\n",
    "list_subfig[2].set_xlabel(\"Total Stops\")\n",
    "list_subfig[2].set_ylabel(\"Total Wins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression 1: Total Pit Time and Total Wins with summary\n",
    "results_pit_time = smf.ols(\"total_wins ~ total_pit_time\", data=agg_table).fit()\n",
    "print(results_pit_time.params)\n",
    "print(results_pit_time.summary())\n",
    "\n",
    "# Linear Regression 2: Total Stops and Total Wins with summary\n",
    "results_stops = smf.ols(\"total_wins ~ total_stops\", data=agg_table).fit()\n",
    "print(results_stops.params)\n",
    "print(results_stops.summary())\n",
    "\n",
    "\n",
    "# Find line of best fit parameters for Regression 1\n",
    "m = results_pit_time.params[\"total_pit_time\"]\n",
    "b = results_pit_time.params[\"Intercept\"]\n",
    "\n",
    "# Find line of best fit parameters for Regression 2\n",
    "m1 = results_stops.params[\"total_stops\"]\n",
    "b1 = results_stops.params[\"Intercept\"]\n",
    "\n",
    "\n",
    "#Subplot of Linear Regression 1 and 2 Visualization\n",
    "fig, list_subfig = plt.subplots(1, 2, figsize = (9,3))\n",
    "\n",
    "list_subfig[0].scatter(agg_table[\"total_pit_time\"], agg_table[\"total_wins\"])\n",
    "list_subfig[0].plot(agg_table[\"total_pit_time\"], m * agg_table[\"total_pit_time\"] + b, color=\"red\")\n",
    "list_subfig[0].set_title(\"Total Stops vs. Total Wins\")\n",
    "list_subfig[0].set_xlabel(\"Total Pit Time\")\n",
    "list_subfig[0].set_ylabel(\"Total Wins\")\n",
    "\n",
    "list_subfig[1].scatter(agg_table[\"total_stops\"], agg_table[\"total_wins\"])\n",
    "list_subfig[1].plot(agg_table[\"total_stops\"], m1 * agg_table[\"total_stops\"] + b1, color=\"red\")\n",
    "list_subfig[1].set_title(\"Linear Regression of Total Stops vs. Total Wins\")\n",
    "list_subfig[1].set_xlabel(\"Total Stops\")\n",
    "list_subfig[1].set_ylabel(\"Total Wins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Parsing/Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DISCUSSION\n",
    "\n",
    "Tammy: By taking the csv datasets, driver_standings and pit_stops, we merged them by grouping driverId and raceId and stored them into variable merged_f1. Using this merged dataset, we created some data description diagnostic commands to be used for reference when parsing and cleaning the dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
